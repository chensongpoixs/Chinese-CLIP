{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36166fed",
   "metadata": {},
   "source": [
    "!@pip install modelscope\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2407f20",
   "metadata": {},
   "source": [
    "!pip install modelscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424b48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c551b0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: ['ViT-B-16', 'ViT-L-14', 'ViT-L-14-336', 'ViT-H-14', 'RN50']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Ckpt download requires `modelscope`. Please install `modelscope` or download the ckpt manually and provide the local path so that we can continue.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Work\\AI\\stable_diffusion\\stable-diffusion-webui\\Chinese-CLIP\\cn_clip\\clip\\utils.py:67\u001b[0m, in \u001b[0;36m_download\u001b[1;34m(modelname, root, use_modelscope)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_download\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model_file_download\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'modelscope'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 如本地模型不存在，自动从ModelScope下载模型，需要提前安装`modelscope`包\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m model, preprocess \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mViT-B-16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_modelscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     13\u001b[0m image \u001b[38;5;241m=\u001b[39m preprocess(Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexamples/pokemon.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mD:\\Work\\AI\\stable_diffusion\\stable-diffusion-webui\\Chinese-CLIP\\cn_clip\\clip\\utils.py:109\u001b[0m, in \u001b[0;36mload_from_name\u001b[1;34m(name, device, download_root, vision_model_name, text_model_name, input_resolution, use_modelscope)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_from_name\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m, device: Union[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    107\u001b[0m                    download_root: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, vision_model_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, text_model_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, input_resolution: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, use_modelscope: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _MODELS:\n\u001b[1;32m--> 109\u001b[0m         model_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpanduser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m~/.cache/clip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_modelscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m         model_name, model_input_resolution \u001b[38;5;241m=\u001b[39m _MODEL_INFO[name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstruct\u001b[39m\u001b[38;5;124m'\u001b[39m], _MODEL_INFO[name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_resolution\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(name):\n",
      "File \u001b[1;32mD:\\Work\\AI\\stable_diffusion\\stable-diffusion-webui\\Chinese-CLIP\\cn_clip\\clip\\utils.py:69\u001b[0m, in \u001b[0;36m_download\u001b[1;34m(modelname, root, use_modelscope)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_download\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model_file_download\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _:\n\u001b[1;32m---> 69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCkpt download requires `modelscope`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install `modelscope` or download the ckpt manually and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovide the local path so that we can continue.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     75\u001b[0m     local_path \u001b[38;5;241m=\u001b[39m model_file_download(\n\u001b[0;32m     76\u001b[0m         model_id\u001b[38;5;241m=\u001b[39m_MODELSCOPE_ORG \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m reponame,\n\u001b[0;32m     77\u001b[0m         file_path\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m     78\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mroot,\n\u001b[0;32m     79\u001b[0m     )\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Ckpt download requires `modelscope`. Please install `modelscope` or download the ckpt manually and provide the local path so that we can continue."
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from PIL import Image\n",
    "\n",
    "import cn_clip.clip as clip\n",
    "from cn_clip.clip import load_from_name, available_models\n",
    "print(\"Available models:\", available_models())  \n",
    "# Available models: ['ViT-B-16', 'ViT-L-14', 'ViT-L-14-336', 'ViT-H-14', 'RN50']\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 如本地模型不存在，自动从ModelScope下载模型，需要提前安装`modelscope`包\n",
    "model, preprocess = load_from_name(\"ViT-B-16\", device=device, download_root='./', use_modelscope=True)\n",
    "model.eval()\n",
    "image = preprocess(Image.open(\"examples/pokemon.jpeg\")).unsqueeze(0).to(device)\n",
    "text = clip.tokenize([\"杰尼龟\", \"妙蛙种子\", \"小火龙\", \"皮卡丘\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    # 对特征进行归一化，请使用归一化后的图文特征用于下游任务\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True) \n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)    \n",
    "\n",
    "    logits_per_image, logits_per_text = model.get_similarity(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # [[1.268734e-03 5.436878e-02 6.795761e-04 9.436829e-01]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcf5336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable-diffusion-webui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
